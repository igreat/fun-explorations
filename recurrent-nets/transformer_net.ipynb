{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where I'll build a transformer based neural network for producing toy story like text\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Masked Self Attention\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, head_dim, max_seq_len):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Linear(input_dim, head_dim)\n",
    "        self.key = nn.Linear(input_dim, head_dim)\n",
    "        self.value = nn.Linear(input_dim, head_dim)\n",
    "\n",
    "        self.register_buffer('mask', torch.tril(torch.ones(max_seq_len, max_seq_len)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        # (batch_size, seq_len, seq_len)\n",
    "        similarity_scores = q @ k.transpose(1, 2)\n",
    "        # mask out future tokens to float('-inf')\n",
    "        seq_len = similarity_scores.shape[1]\n",
    "        similarity_scores = similarity_scores.masked_fill(self.mask[:seq_len, :seq_len] == 0, float('-inf'))\n",
    "        attention_weights = F.softmax(similarity_scores, dim=1)\n",
    "        output = attention_weights @ v # (batch_size, seq_len, value_dim)\n",
    "        return output\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, head_dim, max_seq_len, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.self_attention_heads = nn.ModuleList(\n",
    "            [SelfAttention(input_dim, head_dim, max_seq_len) for _ in range(num_heads)]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (batch_size, seq_len, query_dim)\n",
    "        # multi head self attention\n",
    "        output = torch.cat([head(x) for head in self.self_attention_heads], dim=-1)\n",
    "        return output\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, input_dim, head_dim, num_heads, ff_dim):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(input_dim, head_dim, 256, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(input_dim, ff_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim * 4, input_dim)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.attention(x)\n",
    "        x = x + self.norm1(x)\n",
    "        x = self.ff(x)\n",
    "        x = x + self.norm2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168003"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load toy story script as text into a list\n",
    "text: list[str] = []\n",
    "with open(f\"data/toy story.txt\") as f:\n",
    "    text = list(f.read())\n",
    "    \n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FADE IN:\n",
      "\n",
      "INT. ANDY'S BEDROOM\n",
      "\n",
      "A row of moving boxes lie on the floor of the room.  They\n",
      "are drawn u\n"
     ]
    }
   ],
   "source": [
    "# print first 100 characters\n",
    "print(\"\".join(text[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up table encoder decoder from letters in words to numbers\n",
    "def make_encoder_decoder(words: list[str]) -> tuple[dict[str, int], dict[int, str]]:\n",
    "    letters = sorted(set(\"\".join(words)))\n",
    "    encoder = {letter: i for i, letter in enumerate(letters)}\n",
    "    decoder = {i: letter for i, letter in enumerate(letters)}\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the dataset into sequences\n",
    "def make_sequences(x: torch.Tensor, sequence_size: int) -> torch.Tensor:\n",
    "    sequences = []\n",
    "    for i in range(0, x.shape[0] - sequence_size):\n",
    "        sequences.append(x[i:i+sequence_size])\n",
    "    return torch.stack(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the dataset into mini batches randomly and return the batches\n",
    "def make_batches(x: torch.Tensor, batch_size):\n",
    "    n = x.shape[0]\n",
    "    indices = torch.randperm(n)\n",
    "    x = x[indices]\n",
    "    for i in range(0, n, batch_size):\n",
    "        xs = x[i:i+batch_size]\n",
    "        # batches.append((x[i:i+batch_size, :-1], x[i:i+batch_size, -1]))\n",
    "        yield x[i:i+batch_size, :-1], x[i:i+batch_size, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder = make_encoder_decoder(text)\n",
    "sequence_length = 128\n",
    "# create the dataset\n",
    "all_letters = torch.tensor([encoder[letter] for letter in text], dtype=torch.long)\n",
    "sequences = make_sequences(all_letters, sequence_length + 1).to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(len(encoder), embedding_dim)\n",
    "        self.position_embedding = nn.Embedding(sequence_length, embedding_dim)\n",
    "        num_heads = 4\n",
    "        self.transformer_blocks = nn.Sequential(\n",
    "            TransformerBlock(\n",
    "                embedding_dim*2, \n",
    "                head_dim=(embedding_dim*2)//num_heads, \n",
    "                ff_dim=embedding_dim, \n",
    "                num_heads=num_heads), \n",
    "        )\n",
    "        self.linear = nn.Linear(embedding_dim*2, len(encoder))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T = x.shape\n",
    "\n",
    "        token_emb = self.token_embedding(x) # (B, T, C)\n",
    "        \n",
    "        position_emb = self.position_embedding(torch.arange(T, device=\"mps\")) # (T, C)\n",
    "        position_emb = position_emb.unsqueeze(0).expand(B, -1, -1)  \n",
    "\n",
    "        x = torch.cat([token_emb, position_emb], dim=-1) # (B, T, 2*C)\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "model = Model().to(\"mps\")\n",
    "# set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: [   0/5246], loss: 2.3328\n",
      "epoch: 0, batch: [ 100/5246], loss: 1.9948\n",
      "epoch: 0, batch: [ 200/5246], loss: 1.8148\n",
      "epoch: 0, batch: [ 300/5246], loss: 1.7014\n",
      "epoch: 0, batch: [ 400/5246], loss: 1.2627\n",
      "epoch: 0, batch: [ 500/5246], loss: 0.8450\n",
      "epoch: 0, batch: [ 600/5246], loss: 0.5405\n",
      "epoch: 0, batch: [ 700/5246], loss: 0.3890\n",
      "epoch: 0, batch: [ 800/5246], loss: 0.3514\n",
      "epoch: 0, batch: [ 900/5246], loss: 0.2569\n",
      "epoch: 0, batch: [1000/5246], loss: 0.2119\n",
      "epoch: 0, batch: [1100/5246], loss: 0.1632\n",
      "epoch: 0, batch: [1200/5246], loss: 0.1411\n",
      "epoch: 0, batch: [1300/5246], loss: 0.1233\n",
      "epoch: 0, batch: [1400/5246], loss: 0.1139\n",
      "epoch: 0, batch: [1500/5246], loss: 0.0968\n",
      "epoch: 0, batch: [1600/5246], loss: 0.0924\n",
      "epoch: 0, batch: [1700/5246], loss: 0.0870\n",
      "epoch: 0, batch: [1800/5246], loss: 0.0714\n",
      "epoch: 0, batch: [1900/5246], loss: 0.0666\n",
      "epoch: 0, batch: [2000/5246], loss: 0.0692\n",
      "epoch: 0, batch: [2100/5246], loss: 0.0564\n",
      "epoch: 0, batch: [2200/5246], loss: 0.0477\n",
      "epoch: 0, batch: [2300/5246], loss: 0.0492\n",
      "epoch: 0, batch: [2400/5246], loss: 0.0456\n",
      "epoch: 0, batch: [2500/5246], loss: 0.0463\n",
      "epoch: 0, batch: [2600/5246], loss: 0.0505\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mujtabaalajmi/Desktop/MACHINE LEARNING/fun explorations/recurrent-nets/transformer_net.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mujtabaalajmi/Desktop/MACHINE%20LEARNING/fun%20explorations/recurrent-nets/transformer_net.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iters):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mujtabaalajmi/Desktop/MACHINE%20LEARNING/fun%20explorations/recurrent-nets/transformer_net.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch_num, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(make_batches(sequences, batch_size)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mujtabaalajmi/Desktop/MACHINE%20LEARNING/fun%20explorations/recurrent-nets/transformer_net.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         logits \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mujtabaalajmi/Desktop/MACHINE%20LEARNING/fun%20explorations/recurrent-nets/transformer_net.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         B, T, C \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39mshape\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mujtabaalajmi/Desktop/MACHINE%20LEARNING/fun%20explorations/recurrent-nets/transformer_net.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         logits \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39mview(B\u001b[39m*\u001b[39mT, C)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-nightly/lib/python3.9/site-packages/torch/nn/modules/module.py:1488\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1486\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1487\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1488\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1489\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/mujtabaalajmi/Desktop/MACHINE LEARNING/fun explorations/recurrent-nets/transformer_net.ipynb Cell 12\u001b[0m in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mujtabaalajmi/Desktop/MACHINE%20LEARNING/fun%20explorations/recurrent-nets/transformer_net.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mujtabaalajmi/Desktop/MACHINE%20LEARNING/fun%20explorations/recurrent-nets/transformer_net.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     B, T \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mujtabaalajmi/Desktop/MACHINE%20LEARNING/fun%20explorations/recurrent-nets/transformer_net.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     token_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken_embedding(x) \u001b[39m# (B, T, C)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mujtabaalajmi/Desktop/MACHINE%20LEARNING/fun%20explorations/recurrent-nets/transformer_net.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     position_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding(torch\u001b[39m.\u001b[39marange(T, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39m# (T, C)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mujtabaalajmi/Desktop/MACHINE%20LEARNING/fun%20explorations/recurrent-nets/transformer_net.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     position_emb \u001b[39m=\u001b[39m position_emb\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mexpand(B, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-nightly/lib/python3.9/site-packages/torch/nn/modules/module.py:1488\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1486\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1487\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1488\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1489\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-nightly/lib/python3.9/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch-nightly/lib/python3.9/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "max_iters = 25\n",
    "batch_size = 32\n",
    "num_batches = sequences.shape[0] // batch_size\n",
    "model.train().to(\"mps\")\n",
    "for i in range(max_iters):\n",
    "    for batch_num, (x, y) in enumerate(make_batches(sequences, batch_size)):\n",
    "        logits = model(x)\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        y = y.flatten()\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if batch_num % 100 == 0:\n",
    "            print(f\"epoch: {i}, batch: [{batch_num:>4d}/{num_batches:>4d}], loss: {loss.item():.4f}\")\n",
    "    \n",
    "    print(f\"epoch: {i}, loss: {loss.item()}\")\n",
    "\n",
    "# save checkpoint of model (optimizer and model state dict)\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    \"loss\": loss\n",
    "}, \"checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_text(model, start_text, max_len=200):\n",
    "    model.eval()\n",
    "    text = start_text\n",
    "    for i in range(max_len):\n",
    "        x = torch.tensor([encoder[letter] for letter in text[-sequence_length:]], dtype=torch.long).to(\"mps\")\n",
    "        x = x.unsqueeze(0)\n",
    "        logits = model(x)\n",
    "        logits = logits[:, -1, :]\n",
    "        # sample from the distribution\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        letter = torch.multinomial(probs, 1).squeeze(0)[-1]\n",
    "        text += decoder[letter.item()]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A row of moving boxes lie on the floor of the room. \\nThey are drawnaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa,\"TISSSSRS\\nof hyalce PCA,\\n  DES\\nchacks rure haynhe rally Doe rup the dre rome re     SSYISSS PIElly widdles thr        HEyaly 6yy, is mimsind dey '"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, \"A row of moving boxes lie on the floor of the room. They are drawn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b69368623ed639ee298e27c6826506e73bcdec6b9db0563c29b08757f48e8ce8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
